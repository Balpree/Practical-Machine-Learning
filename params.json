{"name":"Practical-machine-learning","tagline":"","body":"# Practical Machine Learning Project\r\nMichael Goodman  \r\nTuesday, May 19, 2015  \r\n\r\n# Executive Summary\r\n#### GitHub Repo: <https://github.com/MGoodman10/Practical-Machine-Learning>\r\n\r\n###Background  \r\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible \r\nto collect a large amount of data about personal activity relatively \r\ninexpensively. These type of devices are part of the quantified self \r\nmovement - a group of enthusiasts who take measurements about themselves \r\nregularly to improve their health, to find patterns in their behavior, or \r\nbecause they are tech geeks. One thing that people regularly do is quantify \r\nhow much of a particular activity they do, but they rarely quantify how well \r\nthey do it. The goal of this project is to use data from accelerometers \r\non the belt, forearm, arm, and dumbbell of 6 participants as they \r\nperform barbell lifts correctly and incorrectly 5 different ways. \r\n\r\nSix young healthy participants were asked to perform one set of 10 repetitions \r\nof the Unilateral Dumbbell Biceps Curl in five different fashions:  \r\n* Class A - exactly according to the specification  \r\n* Class B - throwing the elbows to the front  \r\n* Class C - lifting the dumbbell only halfway  \r\n* Class D - lowering the dumbbell only halfway  \r\n* Class E - throwing the hips to the front  \r\n  \r\nClass A corresponds to the specified execution of the exercise, while the other \r\n4 classes correspond to common mistakes. Participants were supervised by \r\nan experienced weight lifter to make sure the execution complied to the \r\nmanner they were supposed to simulate. The exercises were performed by six \r\nmale participants aged between 20-28 years, with little weight lifting \r\nexperience. Researchers made sure that all participants could easily simulate \r\nthe mistakes in a safe and controlled manner by using a relatively light \r\ndumbbell (1.25kg).\r\n\r\n### Reference  \r\nVelloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative \r\nActivity Recognition of Weight Lifting Exercises. Proceedings of 4th \r\nInternational Conference in Cooperation with SIGCHI (Augmented Human '13).\r\nStuttgart, Germany: ACM SIGCHI, 2013.\r\n\r\n### Data  \r\n\r\nThe training data for this project are available at: \r\n\r\n<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>\r\n\r\nThe test data are available at: \r\n\r\n<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>\r\n\r\n### Goal\r\n\r\nThe goal of this project is to predict the manner in which subjects did \r\nthe exercise. This is the \"classe\" variable in the training set. The model will\r\nuse the other variables to predict with. This report describes:  \r\n* how the model is built  \r\n* use of cross validation  \r\n* an estimate of expected out of sample error  \r\n\r\n# Getting and cleaning the Data\r\nThe first step is to download the data, load it into R and prepare it for \r\nthe modeling process.  \r\n\r\n### Load the functions and static variables\r\nAll functions are loaded and static variables are assigned.  Also in this \r\nsection, the seed is set so the pseudo-random number generator operates in a \r\nconsistent way for repeat-ability.  \r\n\r\n\r\n```r\r\nlibrary(caret)\r\nlibrary(rpart)\r\nlibrary(rpart.plot)\r\nlibrary(RColorBrewer)\r\nlibrary(rattle)\r\nlibrary(e1071)\r\nlibrary(randomForest)\r\nset.seed(1)\r\n\r\ntrain.url <-\r\n        \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\r\ntest.url <- \r\n        \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\r\n\r\npath <- paste(getwd(),\"/\", \"machine\", sep=\"\")\r\ntrain.file <- file.path(path, \"machine-train-data.csv\")\r\ntest.file <- file.path(path, \"machine-test-data.csv\")\r\n```\r\n\r\n### Dowload the files (if necessary) and read them into memory  \r\nThe files are read into memory.  Various indicators of missing data (i.e., \r\n\"NA\", \"#DIV/0!\" and \"\") are all set to NA so they can be processed.  \r\n\r\n\r\n```r\r\nif (!file.exists(train.file)) {\r\n        download.file(train.url, destfile=train.file)\r\n}\r\nif (!file.exists(test.file)) {\r\n        download.file(test.url, destfile=test.file)\r\n}\r\n\r\ntrain.data.raw <- read.csv(train.file, na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\r\ntest.data.raw <- read.csv(test.file, na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\r\n```\r\n\r\n### Remove unecessary colums\r\nColumns that are not deeded for the model and columns that contain NAs \r\nare eliminated.  \r\n\r\n\r\n```r\r\n# Drop the first 7 columns as they're unnecessary for predicting.\r\ntrain.data.clean1 <- train.data.raw[,8:length(colnames(train.data.raw))]\r\ntest.data.clean1 <- test.data.raw[,8:length(colnames(test.data.raw))]\r\n\r\n# Drop colums with NAs\r\ntrain.data.clean1 <- train.data.clean1[, colSums(is.na(train.data.clean1)) == 0] \r\ntest.data.clean1 <- test.data.clean1[, colSums(is.na(test.data.clean1)) == 0] \r\n\r\n# Check for near zero variance predictors and drop them if necessary\r\nnzv <- nearZeroVar(train.data.clean1,saveMetrics=TRUE)\r\nzero.var.ind <- sum(nzv$nzv)\r\n\r\nif ((zero.var.ind>0)) {\r\n        train.data.clean1 <- train.data.clean1[,nzv$nzv==FALSE]\r\n}\r\n```\r\n\r\n### Slice the data for cross validation  \r\nThe training data is divided into two sets.  This first is a training set with 70% of the data which is used to train the model.  The second is a validation \r\nset used to assess model performance.  \r\n\r\n\r\n```r\r\nin.training <- createDataPartition(train.data.clean1$classe, p=0.70, list=F)\r\ntrain.data.final <- train.data.clean1[in.training, ]\r\nvalidate.data.final <- train.data.clean1[-in.training, ]\r\n```\r\n\r\n# Model Development  \r\n### Train the model  \r\nThe training data-set is used to fit a Random Forest model because it \r\nautomatically selects important variables and is robust to correlated \r\ncovariates & outliers in general. 5-fold cross validation is used when \r\napplying the algorithm. A Random Forest algorithm is a way of averaging \r\nmultiple deep decision trees, trained on different parts of the same data-set,\r\nwith the goal of reducing the variance. This typically produces better \r\nperformance at the expense of bias and interpret-ability. The Cross-validation \r\ntechnique assesses how the results of a statistical analysis will generalize \r\nto an independent data set. In 5-fold cross-validation, the original sample \r\nis randomly partitioned into 5 equal sized sub-samples. a single sample \r\nis retained for validation and the other sub-samples are used as training \r\ndata. The process is repeated 5 times and the results from the folds are \r\naveraged.\r\n\r\n\r\n```r\r\ncontrol.parms <- trainControl(method=\"cv\", 5)\r\nrf.model <- train(classe ~ ., data=train.data.final, method=\"rf\",\r\n                 trControl=control.parms, ntree=251)\r\nrf.model\r\n```\r\n\r\n```\r\n## Random Forest \r\n## \r\n## 13737 samples\r\n##    52 predictor\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (5 fold) \r\n## \r\n## Summary of sample sizes: 10990, 10990, 10989, 10990, 10989 \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   \r\n##    2    0.9905366  0.9880275  0.001543981  0.001955033\r\n##   27    0.9906094  0.9881210  0.001295651  0.001638512\r\n##   52    0.9828201  0.9782677  0.004693225  0.005936194\r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 27.\r\n```\r\n\r\n### Estimate performance  \r\nThe model fit using the training data is tested against the validation data.\r\nPredicted values for the validation data are then compared to the actual \r\nvalues. This allows forecasting the accuracy and overall out-of-sample error,\r\nwhich indicate how well the model will perform with other data.  \r\n\r\n\r\n```r\r\nrf.predict <- predict(rf.model, validate.data.final)\r\nconfusionMatrix(validate.data.final$classe, rf.predict)\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1670    1    2    0    1\r\n##          B    5 1130    3    1    0\r\n##          C    0    7 1016    3    0\r\n##          D    0    0    4  957    3\r\n##          E    0    1    2    2 1077\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9941          \r\n##                  95% CI : (0.9917, 0.9959)\r\n##     No Information Rate : 0.2846          \r\n##     P-Value [Acc > NIR] : < 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9925          \r\n##  Mcnemar's Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9970   0.9921   0.9893   0.9938   0.9963\r\n## Specificity            0.9990   0.9981   0.9979   0.9986   0.9990\r\n## Pos Pred Value         0.9976   0.9921   0.9903   0.9927   0.9954\r\n## Neg Pred Value         0.9988   0.9981   0.9977   0.9988   0.9992\r\n## Prevalence             0.2846   0.1935   0.1745   0.1636   0.1837\r\n## Detection Rate         0.2838   0.1920   0.1726   0.1626   0.1830\r\n## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839\r\n## Balanced Accuracy      0.9980   0.9951   0.9936   0.9962   0.9976\r\n```\r\n\r\n```r\r\naccuracy <- postResample(rf.predict, validate.data.final$classe)\r\nacc.out <- accuracy[1]\r\n\r\noverall.ose <- \r\n        1 - as.numeric(confusionMatrix(validate.data.final$classe, rf.predict)\r\n                       $overall[1])\r\n```\r\n\r\n### Results  \r\nThe accuracy of this model is **0.9940527** and the Overall Out-of-Sample \r\nerror is **0.0059473**.\r\n\r\n# Run the model\r\nThe model is applied to the test data to produce the results.\r\n\r\n\r\n```r\r\nresults <- predict(rf.model, \r\n                   test.data.clean1[, -length(names(test.data.clean1))])\r\nresults\r\n```\r\n\r\n```\r\n##  [1] B A B A A E D B A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n```\r\n\r\n# Appendix - Decision Tree Visualization\r\n\r\n\r\n```r\r\ntreeModel <- rpart(classe ~ ., data=train.data.final, method=\"class\")\r\nfancyRpartPlot(treeModel)\r\n```\r\n\r\n![](machine_proj_1_files/figure-html/unnamed-chunk-8-1.png) \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}